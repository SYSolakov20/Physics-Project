This is information about our voltmeter simulation
A voltmeter is an instrument used for measuring electric potential difference between two points in an
electric circuit. It is connected in parallel. It usually has a high resistance so that it takes 
negligible current from the circuit.
Analog voltmeters move a pointer across a scale in proportion to the voltage measured and can be 
built from a galvanometer and series resistor. Meters using amplifiers can measure tiny voltages of 
microvolts or less. Digital voltmeters give a numerical display of voltage by use of an 
analog-to-digital converter.
Voltmeters are made in a wide range of styles, some separately powered (e.g. by battery), and others 
powered by the measured voltage source itself. Instruments permanently mounted in a panel are used to 
monitor generators or other fixed apparatus. Portable instruments, usually equipped to also measure 
current and resistance in the form of a multimeter, are standard test instruments used in electrical 
and electronics work. Any measurement that can be converted to a voltage can be displayed on a meter 
that is suitably calibrated; for example, pressure, temperature, flow or level in a chemical process 
plant.
General-purpose analog voltmeters may have an accuracy of a few percent of full scale and are used 
with voltages from a fraction of a volt to several thousand volts. Digital meters can be made with 
high accuracy, typically better than 1%. Specially calibrated test instruments have higher accuracies,
with laboratory instruments capable of measuring to accuracies of a few parts per million. Part of the
problem of making an accurate voltmeter is that of calibration to check its accuracy. In laboratories,
the Weston cell is used as a standard voltage for precision work. Precision voltage references are
available based on electronic circuits.